#!/bin/bash

# The full path of the lock file to use.
LOCKFILE="/root/lambda-lock"

# The full path of the log file.
LOGFILE="/root/lambda-init-log"

log(){
  message=$1
  echo "$(date): $message" >> $LOGFILE
}

start(){
  # Assert that there is no other Lambda instance, created with this script, running.
  if [ -f $LOCKFILE ]
    then
      return 0
  fi

  # Start Apache HDFS.
  log "Starting Apache HDFS..."
  /etc/init.d/hdfs-init start
  returnedValue=$?
  if [ $returnedValue -eq 0 ]
  then
    log "Apache HDFS has been started!"

    # Force Apache HDFS to exit safe mode so that Apache Flink can be started later on this script.
    {{ hadoop_home }}/bin/hdfs dfsadmin -safemode leave
  else
    log "Apache HDFS has failed to start with returned code $returnedValue."
  fi

  # Start Apache Yarn.
  log "Starting Apache Yarn..."
  /etc/init.d/yarn-init start
  returnedValue=$?
  if [ $returnedValue -eq 0 ]
  then
    log "Apache Yarn has been started!"
  else
    log "Apache Yarn has failed to start with returned code $returnedValue."
  fi

  # Start supervisord on master node.
  log "Starting Supervisord..."
  supervisord -c /etc/supervisor/supervisord.conf --logfile=/root/supervisord.log
  returnedValue=$?
  if [ $returnedValue -eq 0 ]
  then
    log "Supervisord on master node has been started!"
  else
    log "Supervisord on master node has failed to start with returned code $returnedValue."
  fi

  # Start Apache Zookeeper.
  log "Starting Apache Zookeeper..."
  supervisorctl start apache_zookeeper
  # Wait for Apache Zookeeper to start.
  while [ "$(supervisorctl status apache_zookeeper | tr -s ' ' | cut -f2 -d' ')" == "STARTING" ] 
  do
    sleep 10
  done
  apache_zookeeper_status=$(supervisorctl status apache_zookeeper | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_zookeeper_status" != "RUNNING" ]
  then
    log "Apache Zookeeper has failed to start with code $apache_zookeeper_status."
  else
    log "Apache Zookeeper has been started!"
  fi

  # Start Apache Kafka on master node.
  log "Starting Apache kafka..."
  supervisorctl start apache_kafka
  # Wait for Apache Kafka to start.
  while [ "$(supervisorctl status apache_kafka | tr -s ' ' | cut -f2 -d' ')" == "STARTING" ] 
  do
    sleep 10
  done
  apache_kafka_status=$(supervisorctl status apache_kafka | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_kafka_status" != "RUNNING" ]
  then
    log "Apache kafka has failed to start with code $apache_kafka_status."
  else
    log "Apache kafka has been started!"
  fi

  # Start Apache Kafka on each slave node.
  for node in $(cat /etc/hosts | grep "snf" | cut -f2)
  do
    if [ "$node" == "$(hostname).local" ]
    then
      continue
    fi
    log "Starting Apache Kafka at $node..."
    ssh -l root $node supervisord -c /etc/supervisor/supervisord.conf --logfile=/root/supervisord.log
    log "Supervisord on $node has been started!"
    ssh -l root $node supervisorctl start apache_kafka
   # Wait for Apache kafka to start.
   while [ "$(ssh -l root $node supervisorctl status apache_kafka | tr -s ' ' | cut -f2 -d' ')" == "STARTING" ] 
   do
     sleep 10
   done
   apache_kafka_status=$(ssh -l root $node supervisorctl status apache_kafka | tr -s ' ' | cut -f2 -d' ') 
   if [ "$apache_kafka_status" != "RUNNING" ]
   then
     log "Apache Kafka at $node has failed to start with code $apache_kafka_status."
   else
     log "Apache Kafka at $node has been started!"
   fi
  done

  # Start Apache Flink.
  log "Starting Apache Flink..."
  supervisorctl start apache_flink
  # Wait for Apache Flink to start.
  while [ "$(supervisorctl status apache_flink | tr -s ' ' | cut -f2 -d' ')" == "STARTING" ] 
  do
    sleep 10
  done
  apache_flink_status=$(supervisorctl status apache_flink | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_flink_status" != "RUNNING" ]
  then
    log "Apache Flink has failed to start with code $apache_flink_status."
  else
    log "Apache Flink has been started!"
  fi

  # Start Apache Flume.
  log "Starting Apache Flume..."
  supervisorctl start apache_flume
  # Wait for Apache Flume to start.
  while [ "$(supervisorctl status apache_flume | tr -s ' ' | cut -f2 -d' ')" == "STARTING" ]
  do
    sleep 10
  done
  apache_flume_status=$(supervisorctl status apache_flume | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_flume_status" != "RUNNING" ]
  then
    log "Apache Flume has failed to start with code $apache_flume_status."
  else
    log "Apache Flume has been started!"
  fi

  # Create a lock file to prevent multiple instantiations.
  touch $LOCKFILE

  return 0
}

stop(){
  # Assert that a lambda instance has been started with this script.
  if [ ! -f $LOCKFILE ]
    then
      return 0
  fi

  # Stop Apache Flink.
  log "Stopping Apache Flink..."
  supervisorctl stop apache_flink
  apache_flink_status=$(supervisorctl status apache_flink | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_flink_status" == "STOPPED" ]
  then
    log "Apache Flink has been stopped!"
  else
    log "Apache Flink has failed to stop with returned code $apache_flink_status."
  fi

  # Stop Apache Yarn.
  log "Stopping Apache Yarn..."
  /etc/init.d/yarn-init stop
  returnedValue=$?
  if [ $returnedValue -eq 0 ]
  then
    log "Apache Yarn has been stopped!"
  else
    log "Apache Yarn has failed to stop with returned code $returnedValue."
  fi

  # Stop Apache HDFS.
  log "Stopping Apache HDFS..."
  /etc/init.d/hdfs-init stop
  returnedValue=$?
  if [ $returnedValue -eq 0 ]
  then
    log "Apache HDFS has been stopped!"
  else
    log "Apache HDFS has failed to stop with returned code $returnedValue."
  fi

  # Stop Apache Kafka on master node.
  supervisorctl stop apache_kafka
  apache_kafka_status=$(supervisorctl status apache_kafka | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_kafka_status" == "STOPPED" ]
  then
    log "Apache kafka has been stopped!"
  else
    log "Apache kafka has failed to stop with returned code $apache_kafka_status"
  fi

  # Stop Apache Kafka on each slave node.
  for node in $(cat /etc/hosts | grep "snf" | cut -f2)
  do
    if [ "$node" == "$(hostname).local" ]
    then
      continue
    fi
    log "Stopping Apache Kafka at $node..."
    ssh -l root $node supervisorctl stop apache_kafka
    apache_kafka_status=$(ssh -l root $node supervisorctl status apache_kafka | tr -s ' ' | cut -f2 -d' ')
    log "Stopping Supervisord at $node..."
    ssh -l root $node supervisorctl shutdown
    if [ "$apache_kafka_status" == "STOPPED" ]
    then
      log "Apache Kafka at $node has been stopped!"
    else
      log "Apache Kafka at $node has failed to stop with returned code $apache_kafka_status"
    fi
  done

  # Stop Apache Zookeeper.
  supervisorctl stop apache_zookeeper
  apache_zookeeper_status=$(supervisorctl status apache_zookeeper | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_zookeeper_status" == "STOPPED" ]
  then
    log "Apache Zookeeper has been stopped!"
  else
    log "Apache Zookeeper has failed to stop with returned code $apache_zookeeper_status"
  fi

  # Stop Apache Flume.
  supervisorctl stop apache_flume
  apache_flume_status=$(supervisorctl status flume_zookeeper | tr -s ' ' | cut -f2 -d' ')
  if [ "$apache_flume_status" == "STOPPED" ]
  then
    log "Apache Flume has been stopped!"
  else
    log "Apache Flume has failed to stop with returned code $apache_flume_status"
  fi

  # Stop Supervisord on master node.
  supervisorctl shutdown
  returnedValue=$?
  if [ $returnedValue -eq 0 ]
  then
    log "Supervisord on master node has been stopped!"
  else
    log "Supervisord on master node has failed to stop with returned code $returnedValue."
  fi

  # Remove lock file.
  rm -f $LOCKFILE

  return 0
}

restart(){
  stop
  start
}

RETVAL=0

case "$1" in
  start)
    start
    ;;
  stop)
    stop
    ;;
  restart|reload|force-reload)
    restart
    ;;
  condrestart)
    [ -f $LOCKFILE ] && restart || :
    ;;
  status)
    # If the lock file exists, then the Lambda instance is running.
    [ -f $LOCKFILE ] && echo "Lambda instance is running." || echo "Lambda instance is not running."
    RETVAL=$?
    ;;
  *)
    echo "Usage: $0 {start|stop|status|restart|reload|force-reload|condrestart}"
    RETVAL=1
esac

exit $RETVAL

